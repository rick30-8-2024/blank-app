{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Organizer import Organizer\n",
    "from search_agent import Research_Tool\n",
    "import random\n",
    "LENGTHY_SEARCH_PROMPT = \"\"\"\n",
    "                            Answer this question in this format:\n",
    "                            {\"status\":\"pending\", \"urls\": list(str)}\n",
    "                            YOU MUST PUT THE JSON ANSWER WITHIN TWO ```\n",
    "\n",
    "                            Return a list of upto 5 urls from the provided ones that you would like to visit for more Context to answer the following question.\n",
    "                            Question:\n",
    "                            \n",
    "                        \"\"\"\n",
    "\n",
    "\n",
    "Researcher = Organizer()\n",
    "search = Research_Tool()\n",
    "\n",
    "query = \"Tesla by elon musk\"\n",
    "urls = search.search(query, random.randint(10,15))\n",
    "print(urls)\n",
    "data = Researcher.get_filtered_urls(urls, LENGTHY_SEARCH_PROMPT, query)\n",
    "print(data)\n",
    "processed_data = await Researcher.process_url(data)\n",
    "final_report = await Researcher.multi_text_processor(query)\n",
    "\n",
    "\n",
    "final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import jsbeautifier\n",
    "from urllib.parse import urlparse, urljoin, quote_plus\n",
    "from typing import Dict, Any, List\n",
    "import requests\n",
    "\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "def log_debug(message):\n",
    "    if DEBUG:\n",
    "        print(f\"DEBUG: {message}\")\n",
    "\n",
    "headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Referer': 'https://www.google.com/',\n",
    "            'DNT': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        }\n",
    "\n",
    "\n",
    "def _perform_web_search(query: str) -> List[Dict[str, Any]]:\n",
    "    encoded_query = quote_plus(query)\n",
    "    search_url = f\"https://www.google.com/search?q={encoded_query}&tbm=vid\"\n",
    "    log_debug(f\"Search URL: {search_url}\")\n",
    "    \n",
    "    try:\n",
    "        log_debug(\"Sending GET request to Google\")\n",
    "        response = requests.get(search_url, headers=headers, timeout=5)\n",
    "        log_debug(f\"Response status code: {response.status_code}\")\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        log_debug(\"Parsing HTML with BeautifulSoup\")\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        print(soup)\n",
    "        # log_debug(\"Searching for result divs\")\n",
    "        # search_results = []\n",
    "        # for g in soup.find_all('div', class_='g'):\n",
    "        #     log_debug(\"Processing a search result div\")\n",
    "        #     anchor = g.find('a')\n",
    "        #     title = g.find('h3').text if g.find('h3') else 'No title'\n",
    "        #     url = anchor.get('href', 'No URL') if anchor else 'No URL'\n",
    "            \n",
    "        #     description = ''\n",
    "        #     description_div = g.find('div', class_=['VwiC3b', 'yXK7lf'])\n",
    "        #     if description_div:\n",
    "        #         description = description_div.get_text(strip=True)\n",
    "        #     else:\n",
    "        #         description = g.get_text(strip=True)\n",
    "            \n",
    "        #     log_debug(f\"Found result: Title: {title[:30]}..., URL: {url[:30]}...\")\n",
    "        #     search_results.append({\n",
    "        #         'title': title,\n",
    "        #         'description': description,\n",
    "        #         'url': url\n",
    "        #     })\n",
    "        \n",
    "        # log_debug(f\"Successfully retrieved {len(search_results)} search results for query: {query}\")\n",
    "        # return search_results\n",
    "    except requests.RequestException as e:\n",
    "        log_debug(f\"Error performing search: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "_perform_web_search(\"robovan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from utils import split_corpus\n",
    "import concurrent.futures\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "\n",
    "query = \"\"\"Generate me a report within 500 words in JSON format using this schema:\n",
    "            {\"summery\": list({\"heading\": sescription}, ...), \"Images\": list({\"url\": str, \"description\": str}, ...), \"links\": list({\"url\": str, \"description\": str}, ...)}\n",
    "            The Images and the Links Must be Present in the context. if no Image or Link found keep the list empty.\n",
    "            DO NOT USE YOUR KNOWLEDGE TO CONSTRUCT THE ANSWER. USE ONLY WHAT IS PROVIDED IN THE CONTEXT.\n",
    "            add only the image and links that are strongly related to the report topic.\n",
    "            in the summery describe the Report topic based on the provided context briefly within 800 words.\n",
    "            Report Topic:\n",
    "            Elon Musk\"\"\"\n",
    "res = requests.get(\"https://en.wikipedia.org/wiki/Elon_Musk\")\n",
    "\n",
    "data = split_corpus(res.text, max_words=1350)\n",
    "api_keys = open(\"keys.txt\").read().split(\"\\n\")\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "def extract_query(text: str) -> str:\n",
    "    pattern = r\"```(.*?)```\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return matches[0] if matches else text\n",
    "\n",
    "def ask_llm(data):\n",
    "    query, api_key, model, JSON = data\n",
    "    for i in range(5):\n",
    "        SambaNova_Client = openai.OpenAI(\n",
    "                api_key=api_key,\n",
    "                base_url=\"https://api.sambanova.ai/v1\",\n",
    "            )\n",
    "\n",
    "        response = SambaNova_Client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\":\"system\",\"content\": \"You're a advance data analyst.\"},{\"role\":\"user\",\"content\":query}],\n",
    "            temperature =  0.1,\n",
    "            top_p = 0.1,\n",
    "        )\n",
    "        if not JSON:\n",
    "            # print(model)\n",
    "            return response.choices[0].message.content\n",
    "        try:\n",
    "            data = json.loads(extract_query(response.choices[0].message.content))\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(response.choices[0].message.content)\n",
    "\n",
    "final_data = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=len(api_keys)) as executor:\n",
    "        prep = [(i+query, api_keys[m % len(api_keys)], \"Meta-Llama-3.1-405B-Instruct\", True ) for m,i in enumerate(data)]\n",
    "        futures = {executor.submit(ask_llm, task): task for task in prep}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            task = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(result)\n",
    "                final_data.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Task {task} raised an exception: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = split_corpus(str(final_data), max_words=1350)\n",
    "print(len(x))\n",
    "# x_data = []\n",
    "# for m,i in enumerate(x):\n",
    "#     temp =(i+query, api_keys[m % len(api_keys)], \"Meta-Llama-3.1-405B-Instruct\", True )\n",
    "#     res = ask_llm(temp)\n",
    "#     x_data.append(res)\n",
    "# x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = split_corpus(str(final_data), max_words=1350)\n",
    "print(len(y))\n",
    "query = \"\"\"\n",
    "                            {data}\n",
    "                            You have been provided with a report and some images and links related to this question:\n",
    "                            {question}\n",
    "\n",
    "                            your job is to unify them and create a Final report that consists of all three of these in MARKDOWN format.\n",
    "                            Take the images and the link urls from the provided urls only and don't make them up yourself.\n",
    "\n",
    "                            NOTE: PUT THE IMAGE URLS IN A WAY SO THAT THEY CAN BE DISPLAYED DIRETLY ON THE MARKDOWN.\n",
    "                                  PUT THE REFERENCE AS YOU SEE FIT.\n",
    "                                  MAKE THE REPORT LOOK AS HUMAN LIKE AS POSSIBLE.\n",
    "                            \"\"\".format(data = y[0], question = \"Jeff Bezos\")\n",
    "y_data = []\n",
    "for m,i in enumerate(y):\n",
    "    temp =(query, api_keys[m % len(api_keys)], \"Meta-Llama-3.1-405B-Instruct\", False )\n",
    "    res = ask_llm(temp)\n",
    "    y_data.append(res)\n",
    "\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://tse4.mm.bing.net/th?id=OVF.yuvSDIheBKlrRyXfcAaonA&pid=Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m my_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Randomly choose 5 unique elements\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m selected_elements \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(selected_elements)  \u001b[38;5;66;03m# Output will be 5 unique elements from my_list\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/random.py:456\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    454\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    458\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample list\n",
    "my_list = [1, 2, 3, 4]\n",
    "\n",
    "# Randomly choose 5 unique elements\n",
    "selected_elements = random.sample(my_list, 5)\n",
    "\n",
    "print(selected_elements)  # Output will be 5 unique elements from my_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
